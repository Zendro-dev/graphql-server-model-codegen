'use strict';

const _ = require("lodash");
const validatorUtil = require("../../utils/validatorUtil");
const helper = require("../../utils/helper");
const errorHelper = require("../../utils/errors");
const fs = require("fs");
const prestoHelper = require("../../utils/presto_helper");
const path = require("path");
const uuidv4 = require("uuidv4").uuid;
const os = require("os");

const iriRegex = new RegExp('<%- regex -%>');

// An exact copy of the the model definition that comes from the .json file
const definition = <%- definition -%>;
const DataLoader = require("dataloader");
/**
 * module - Creates a class to administer model
 */
module.exports = class <%- adapterName -%> {
  constructor(input) {
    for (let key of Object.keys(input)) {
      this[key] = input[key];
    }
  }

  get storageHandler() {
    return <%- adapterName-%>.storageHandler
  }
 
  /**
  * adapterName - Getter for the name attribute
  *
  * This attribute is needed by the models' index
  * @return {string} The adapterName of the model
  */
  static get adapterName(){
    return "<%- adapterName -%>";
  }

  static get adapterType(){
    return '<%- storageType -%>';
  }

  static recognizeId(iri){
    return iriRegex.test(iri);
  }

  /**
   * Cast JSON string to array for the validation.
   * @param  {object} record  Record with JSON string if necessary.
   * @return {object}         Parsed data record.
   */
  static postReadCast(record) {
    if (!record) {
      return [];
    }
    const column_index = {};
    record[0].map((obj, index) => {
      column_index[obj.name] = index;
    });

    let result = [];
    for (const item of record[1]) {
      let record = {};
      for (const attr in definition.attributes) {
        const type = definition.attributes[attr].replace(/\s+/g, "");
        if (
          type[0] === "[" &&
          item[column_index[attr]] !== undefined &&
          item[column_index[attr]] !== null
        ) {
          record[attr] = JSON.parse(item[column_index[attr]]);
        } else if (type === "DateTime") {
          record[attr] = new Date(item[column_index[attr]]).toISOString();
        } else {
          record[attr] = item[column_index[attr]];
        }
      }
      result.push(record);
    }
    return result;
  }

  <% if (useDataLoader) {%>/**
    * Batch function for readById method.
    * @param  {array} keys  keys from readById method
    * @return {array}       searched results
    */
   static async batchReadById(keys) {
     let queryArg = {
       operator: "in",
       field: <%- adapterName -%>.idAttribute(),
       value: keys.join(),
       valueType: "Array",
     };
     let cursorRes = await <%- adapterName -%>.readAllCursor(queryArg);
     cursorRes = cursorRes.<%- namePl -%>.reduce(
       (map, obj) => ((map[obj[<%- adapterName -%>.idAttribute()]] = obj), map),
       {}
     );
     return keys.map(
       (key) =>
         cursorRes[key] || new Error(`Record with ID = "${key}" does not exist`)
     );
   }
 
   static readByIdLoader = new DataLoader(<%- adapterName -%>.batchReadById, {
     cache: false,
   });

   /**
   * readById - The model implementation for reading a single record given by its ID
   *
   * This method is the implementation for reading a single record for the trino storage type, based on SQL.
   * @param {string} id - The ID of the requested record
   * @return {object} The requested record as an object with the type <%- adapterName -%>, or an error object if the validation after reading fails
   * @throws {Error} If the requested record does not exist
   */
   static async readById(id) {
     return await <%- adapterName -%>.readByIdLoader.load(id);
   }<% } else 
  {%>/**
   * readById - The model implementation for reading a single record given by its ID
   *
   * This method is the implementation for reading a single record for the trino storage type, based on SQL.
   * @param {string} id - The ID of the requested record
   * @return {object} The requested record as an object with the type <%- adapterName -%>, or an error object if the validation after reading fails
   * @throws {Error} If the requested record does not exist
   */
  static async readById(id){
    const query = `SELECT * FROM <%- model_name_in_storage -%> WHERE ${this.idAttribute()} = '${id}'`;
    let item = null;
    try {
      const client = await this.storageHandler;
      item = await prestoHelper.queryData(query, client);

      if (!item) {
        throw new Error(`Record with ID = "${id}" does not exist`);
      }
    } catch (e) {
      throw new Error(e);
    }
    item = <%- adapterName -%>.postReadCast(item)[0];
    return validatorUtil.validateData("validateAfterRead", this, item);
  }<%}-%>
  

  /**
   * countRecords - The model implementation for counting the number of records, possibly restricted by a search term
   *
   * This method is the implementation for counting the number of records that fulfill a given condition, or for all records in the table,
   * for the trino storage type, based on SQL.
   * @param {object} search - The search term that restricts the set of records to be counted - if undefined, all records in the table
   * @param {BenignErrorReporter} benignErrorReporter can be used to generate the standard
   * @return {number} The number of records that fulfill the condition, or of all records in the table
   */
  static async countRecords(search, benignErrorReporter){
    const whereOptions = prestoHelper.searchConditionsToTrino(
      search,
      definition
    );
    const query = `SELECT COUNT(*) AS num FROM <%- model_name_in_storage -%> ${whereOptions}`;
    let num = null;
    try {
      const client = await this.storageHandler;
      const result = await prestoHelper.queryData(query, client);
      num = result[1][0][0];
    } catch (e) {
      throw new Error(e);
    }
    return num;
  }

  /**
   * readAllCursor - The model implementation for searching for records in Trino. This method uses cursor based pagination.
   *
   * @param {object} search - The search condition for which records shall be fetched
   * @param {object} pagination - The parameters for pagination, which can be used to get a subset of the requested record set.
   * @param {BenignErrorReporter} benignErrorReporter can be used to generate the standard
   * @return {object} The set of records, possibly constrained by pagination, with full cursor information for all records
   */
  static async readAllCursor(search, order, pagination, benignErrorReporter){
    let isForwardPagination = helper.isForwardPagination(pagination);
    // build the whereOptions.
    let filter = prestoHelper.searchConditionsToTrino(search, definition);
    let newOrder = isForwardPagination
      ? order
      : helper.reverseOrderConditions(order);
    // depending on the direction build the order object
    let sort = prestoHelper.orderConditionsToTrino(
      newOrder,
      this.idAttribute(),
      isForwardPagination
    );
    let orderFields = newOrder ? newOrder.map((x) => x.field) : [];
    // extend the filter for the given order and cursor
    filter = prestoHelper.cursorPaginationArgumentsToTrino(
      pagination,
      sort,
      filter,
      orderFields,
      this.idAttribute(),
      definition.attributes
    );

    // add +1 to the LIMIT to get information about following pages.
    let limit;
    if (pagination){
      limit = helper.isNotUndefinedAndNotNull(pagination.first)
        ? pagination.first + 1
        : helper.isNotUndefinedAndNotNull(pagination.last)
        ? pagination.last + 1
        : undefined;
    }

    let query = `SELECT * FROM <%- model_name_in_storage -%> ${filter} ${sort}`;
    query += limit ? ` LIMIT ${limit}` : '';
    let result = [];

    const client = await this.storageHandler;
    result = await prestoHelper.queryData(query, client);

    result = <%- adapterName -%>.postReadCast(result);
    // validationCheck after read
    result = await validatorUtil.bulkValidateData(
      "validateAfterRead",
      this,
      result,
      benignErrorReporter
    );
    // get the first record (if exists) in the opposite direction to determine pageInfo.
    // if no cursor was given there is no need for an extra query as the results will start at the first (or last) page.
    let oppResult = [];
    if (pagination && (pagination.after || pagination.before)) {
      // reverse the pagination Arguement. after -> before; set first/last to 0, so LIMIT 1 is executed in the reverse Search
      let oppPagination = helper.reversePaginationArgument({
        ...pagination,
        includeCursor: false,
      });
      let oppForwardPagination = helper.isForwardPagination(oppPagination);
      // build the filter object.
      let oppFilter = prestoHelper.searchConditionsToTrino(search, definition);

      let oppOrder = oppForwardPagination
        ? order
        : helper.reverseOrderConditions(order);
      // depending on the direction build the order object
      let oppSort = prestoHelper.orderConditionsToTrino(
        oppOrder,
        this.idAttribute(),
        oppForwardPagination
      );
      let oppOrderFields = oppOrder ? oppOrder.map((x) => x.field) : [];
      // extend the filter for the given order and cursor
      oppFilter = prestoHelper.cursorPaginationArgumentsToTrino(
        oppPagination,
        oppSort,
        oppFilter,
        oppOrderFields,
        this.idAttribute(),
        definition.attributes
      );
      // add +1 to the LIMIT to get information about following pages.
      let oppLimit;
      if (pagination){
        oppLimit = helper.isNotUndefinedAndNotNull(oppPagination.first)
          ? oppPagination.first + 1
          : helper.isNotUndefinedAndNotNull(oppPagination.last)
          ? oppPagination.last + 1
          : undefined;
      }
      query = `SELECT * FROM <%- model_name_in_storage -%> ${oppFilter} ${oppSort}`;
      query += oppLimit ? ` LIMIT ${limit}` : '';
      oppResult = await prestoHelper.queryData(query, client);
      oppResult = <%- adapterName -%>.postReadCast(oppResult);
    }

    // build the graphql Connection Object
    result = result.map((res) => {
      return new <%- adapterName -%>(res);
    });
    let edges = result.map((res) => {
      return {
        node: res,
        cursor: res.base64Encode(),
      };
    });
    const pageInfo = helper.buildPageInfo(edges, oppResult, pagination);
    return { edges, pageInfo, <%- namePl -%>: edges.map((edge) => edge.node) };
  }

  /**
  * addOne - Not implemented for Trino.
  */
  static async addOne(input){
    throw new Error('Not supported by Trino');
  }

  /**
  * deleteOne - Delete the whole file.
  */
  static async deleteOne(id){
    throw new Error('Not supported by Trino');
  }

  /**
  * updateOne - Not implemented for Trino.
  */
  static async updateOne(input){
    throw new Error('Not supported by Trino');
  }

  /**
  * bulkAddCsv - Add records from csv file
  *
  * @param  {object} context - contextual information, e.g. csv file, record delimiter and column names.
  */
  static async bulkAddCsv(context) {
    throw new Error("Not supported by Trino");
  }

  /**
   * csvTableTemplate - Allows the user to download a template in CSV format with the
   * properties and types of this model.
   *
   * @param {BenignErrorReporter} benignErrorReporter can be used to generate the standard
   * GraphQL output {error: ..., data: ...}. If the function reportError of the benignErrorReporter
   * is invoked, the server will include any so reported errors in the final response, i.e. the
   * GraphQL response will have a non empty errors property.
   */
  static async csvTableTemplate(benignErrorReporter){
      return helper.csvTableTemplate(definition);
  }

  <%- include('./includes/create-models-functions', {model: adapterName}); %>
}