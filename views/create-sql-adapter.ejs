const _ = require('lodash');
const globals = require('../../config/globals');
const Sequelize = require('sequelize');
const dict = require('../../utils/graphql-sequelize-types');
const validatorUtil = require('../../utils/validatorUtil');
const helper = require('../../utils/helper');
const searchArg = require('../../utils/search-argument');
const path = require('path');
const fileTools = require('../../utils/file-tools');
const helpersAcl = require('../../utils/helpers-acl');
const email = require('../../utils/email');
const fs = require('fs');
const os = require('os');
const uuidv4 = require('uuidv4').uuid;
const models = require(path.join(__dirname, '..', 'index.js'));

const remoteZendroURL = "<%- url -%>";
const iriRegex = new RegExp('<%- regex -%>');

// An exact copy of the the model definition that comes from the .json file
const definition = <%- definition -%>;
const DataLoader = require("dataloader");

/**
 * module - Creates a sequelize model
 */

module.exports = class <%- adapterName -%> extends Sequelize.Model{
  /**
    * Initialize sequelize model.
    * @param  {object} sequelize Sequelize instance.
    * @param  {object} DataTypes Allowed sequelize data types.
    * @return {object}           Sequelize model with associations defined
    */
  static init(sequelize, DataTypes){
    return super.init({

        <%if(!defaultId){-%>
        <%- idAttribute -%> : {
          type : Sequelize[ dict['<%- idAttributeType %>'] ],
          primaryKey: true
        },
        <%}-%>
      <% let keys = Object.keys(attributes) -%>
      <%for (let i=0; i< keys.length; i++) {-%>
        <% let type_seq =  attributes[ keys[i] ] -%>
        <% let arrayType = ['[String]', '[Int]', '[Float]', '[Boolean]', '[Date]', '[Time]', '[DateTime]']-%>
        <%=  keys[i] %>: {
          type: Sequelize[ dict['<%= type_seq %>'] ]<% if(type_seq === 'Time' ){-%>,
          get(){
              let <%=  keys[i] %> = this.getDataValue('<%=  keys[i] %>');
              if(<%=  keys[i] %> !== null ){
                let m = moment(<%=  keys[i] %>, "HH:mm:ss.SSS[Z]");
                if(m.isValid()){
                  return m.format("HH:mm:ss.SSS[Z]");
                }
              }
            }
            <%}-%> <% if( arrayType.includes(type_seq)){-%>,
            defaultValue: '[]'
            <%}-%>
        }
        <%if(i !== (keys.length -1) ){ -%>,<%}-%>
      <%}-%>


    },{ <%if(indices !== undefined){let string_indices = indices.map(x => { return "'" + x + "'" }) -%>
      indexes: [<%- string_indices.join() -%> ], <%}-%>
      modelName: "<%- nameLc -%>",
      tableName: "<%-namePl-%>",
      sequelize
     } );
  }

  static get adapterName(){
    return '<%- adapterName -%>';
  }

  static get adapterType(){
    return '<%- storageType -%>';
  }

  /**
    * Get the storage handler, which is a static property of the data model class.
    * @returns sequelize.
    */
  get storageHandler() {
    return this.sequelize;
  }

  /**
    * Cast array to JSON string for the storage.
    * @param  {object} record  Original data record.
    * @return {object}         Record with JSON string if necessary.
    */
  static preWriteCast(record){
    for(let attr in definition.attributes){
      let type = definition.attributes[ attr ].replace(/\s+/g, '');
      if(type[0]==='[' && record[ attr ]!== undefined && record[ attr ]!== null){
        record[ attr ] = JSON.stringify(record[attr]);
      }
    }
    return record;
  }

  /**
  * Cast JSON string to array for the validation.
  * @param  {object} record  Record with JSON string if necessary.
  * @return {object}         Parsed data record.
  */
  static postReadCast(record){
      for(let attr in definition.attributes){
          let type = definition.attributes[ attr ].replace(/\s+/g, '');
          if(type[0]==='[' && record[attr] !== undefined && record[ attr ]!== null){
              record[ attr ] = JSON.parse(record[attr]);
          }
      }
      return record;
  }

  static recognizeId(iri){
    return iriRegex.test(iri);
  }

  <% if (useDataLoader) {%>/**
    * Batch function for readById method.
    * @param  {array} keys  keys from readById method
    * @return {array}       searched results
    */
   static async batchReadById(keys) {
     let queryArg = {
       operator: "in",
       field: <%- adapterName -%>.idAttribute(),
       value: keys.join(),
       valueType: "Array",
     };
     let cursorRes = await <%- adapterName -%>.readAllCursor(queryArg);
     cursorRes = cursorRes.<%- namePl -%>.reduce(
       (map, obj) => ((map[obj[<%- adapterName -%>.idAttribute()]] = obj), map),
       {}
     );
     return keys.map(
       (key) =>
         cursorRes[key] || new Error(`Record with ID = "${key}" does not exist`)
     );
   }
 
   static readByIdLoader = new DataLoader(<%- adapterName -%>.batchReadById, {
     cache: false,
   });

   /**
   * readById - The adapter implementation for reading a single record given by its ID
   *
   * Read a single record by a given ID
   * @param {string} id - The ID of the requested record
   * @return {object} The requested record as an object with the type <%- adapterName -%>, or an error object if the validation after reading fails
   * @throws {Error} If the requested record does not exist
   */
   static async readById(id) {
     return await <%- adapterName -%>.readByIdLoader.load(id);
   }<% } else 
  {%>/**
  * readById - The adapter implementation for reading a single record given by its ID
  *
  * Read a single record by a given ID
  * @param {string} id - The ID of the requested record
  * @return {object} The requested record as an object with the type <%- adapterName -%>, or an error object if the validation after reading fails
  * @throws {Error} If the requested record does not exist
  */
  static async readById(id){
    let item = await <%- adapterName -%>.findByPk(id);
    if (item === null) {
        throw new Error(`Record with ID = "${id}" does not exist`);
    }
    item = <%- adapterName -%>.postReadCast(item)
    return item;
  }<%}-%>

  /**
  * countRecords - The adapter implementation for counting the number of records, possibly restricted by a search term
  *
  * This method is the implementation for counting the number of records that fulfill a given condition, or for all records in the table.
  * @param {object} search - The search term that restricts the set of records to be counted - if undefined, all records in the table
  * @param {BenignErrorReporter} benignErrorReporter can be used to generate the standard
  * @return {number} The number of records that fulfill the condition, or of all records in the table
  */
  static countRecords(search){
    let options = {};

    /*
     * Search conditions
     */
    if (search !== undefined && search !== null) {

      //check
      if(typeof search !== 'object') {
        throw new Error('Illegal "search" argument type, it must be an object.');
      }

      let arg = new searchArg(search);
      let arg_sequelize = arg.toSequelize(<%- adapterName -%>.definition.attributes);
      options['where'] = arg_sequelize;
    }
    return super.count(options);
  }

  /**
  * readAllCursor - The adapter implementation for searching for records. This method uses cursor based pagination.
  *
  * @param {object} search - The search condition for which records shall be fetched
  * @param  {array} order - Type of sorting (ASC, DESC) for each field
  * @param {object} pagination - The parameters for pagination, which can be used to get a subset of the requested record set.
  * @param {BenignErrorReporter} benignErrorReporter can be used to generate the standard
  * @return {object} The set of records, possibly constrained by pagination, with full cursor information for all records
  */
  static async readAllCursor(search, order, pagination){
    // build the sequelize options object for cursor-based pagination
    let options = helper.buildCursorBasedSequelizeOptions(search, order, pagination, this.idAttribute(), <%- adapterName -%>.definition.attributes);
    let records = await super.findAll(options);
    records = records.map(x => <%- adapterName -%>.postReadCast(x))

    // get the first record (if exists) in the opposite direction to determine pageInfo.
    // if no cursor was given there is no need for an extra query as the results will start at the first (or last) page.
    let oppRecords = [];
    if (pagination && (pagination.after || pagination.before)) {
      let oppOptions = helper.buildOppositeSearchSequelize(search, order, {...pagination, includeCursor: false}, this.idAttribute(), <%- adapterName -%>.definition.attributes);
      oppRecords = await super.findAll(oppOptions);
    }
    // build the graphql Connection Object
    let edges = helper.buildEdgeObject(records);
    let pageInfo = helper.buildPageInfo(edges, oppRecords, pagination);
    return {edges, pageInfo, <%- namePl -%>: edges.map((edge) => edge.node)};
  }

  /**
  * addOne - The adapter implementation method for adding a record.
  *
  * @param {object} input - The input object.
  * @return {object} The created record 
  * @throw {Error} If the process fails, an error is thrown
  */
  static async addOne(input){
    input = <%- adapterName -%>.preWriteCast(input)
    try{
      const result = await this.sequelize.transaction( async(t) =>{
        let item = await super.create(input, {transaction:t});
        return item;
      });
      <%- adapterName -%>.postReadCast(result.dataValues)
      <%- adapterName -%>.postReadCast(result._previousDataValues)
      return result;
    }catch(error){
      throw error;
    }

  }

  /**
  * deleteOne - The adapter implementation for deleting a single record, given by its ID.
  *
  * @param {string} id - The ID of the record to be deleted
  * @returns {string} A success message is returned
  * @throw {Error} If the record could not be deleted - this means a record with the ID is still present
  */
  static async deleteOne(id){
    let destroyed = await super.destroy({where:{[this.idAttribute()] : id} });
    if(destroyed !== 0){
      return 'Item successfully deleted';
    }else{
      throw new Error(`Record with ID = ${id} does not exist or could not been deleted`);
    }
  }

  /**
  * updateOne - The adapter implementation for updating a single record.
  *
  * @param {object} input - The input object.
  * @returns {object} The updated record
  * @throw {Error} If this method fails, an error is thrown
  */
  static async updateOne(input){
    input = <%- adapterName -%>.preWriteCast(input)
    try{
      let result = await this.sequelize.transaction( async (t) =>{
        let to_update = await super.findByPk(input[this.idAttribute()]);
        if(to_update === null){
          throw new Error(`Record with ID = ${input[this.idAttribute()]} does not exist`);
        }

        let updated = await to_update.update( input, { transaction: t } );
        return updated;
      });
      <%- adapterName -%>.postReadCast(result.dataValues)
      <%- adapterName -%>.postReadCast(result._previousDataValues)
      return result;
    }catch(error){
      throw error;
    }
  }


  <%#
  /**
   * Add and remove methods for to-one association where the foreign key
   * is stored in this model and therefore this adapter is the responsible to update the foreign key.
   */
  -%>
  <%- include('./includes/create-adapter-fields-mutations', {op: "add"}); %>
  <%- include('./includes/create-adapter-fields-mutations', {op: "remove"}); %>


  /**
  * bulkAddCsv - Add records from csv file
  *
  * @param  {object} context - contextual information, e.g. csv file, record delimiter and column names.
  */
  static bulkAddCsv(context){

      let delim = context.request.body.delim;
      let cols = context.request.body.cols;
      let tmpFile = path.join(os.tmpdir(), uuidv4() + '.csv');

      context.request.files.csv_file.mv(tmpFile).then(() => {

          fileTools.parseCsvStream(tmpFile, this, delim, cols).then((addedZipFilePath) => {
              try {
                  console.log(`Sending ${addedZipFilePath} to the user.`);

                  let attach = [];
                  attach.push({
                      filename: path.basename("added_data.zip"),
                      path: addedZipFilePath
                  });

                  email.sendEmail(helpersAcl.getTokenFromContext(context).email,
                      'ScienceDB batch add',
                      'Your data has been successfully added to the database.',
                      attach).then(function(info) {
                      fileTools.deleteIfExists(addedZipFilePath);
                      console.log(info);
                  }).catch(function(err) {
                      fileTools.deleteIfExists(addedZipFilePath);
                      console.error(err);
                  });

              } catch (error) {
                  console.error(error.message);
              }

              fs.unlinkSync(tmpFile);
          }).catch((error) => {
              email.sendEmail(helpersAcl.getTokenFromContext(context).email,
                  'ScienceDB batch add', `${error.message}`).then(function(info) {
                  console.error(info);
              }).catch(function(err) {
                  console.error(err);
              });

              fs.unlinkSync(tmpFile);
          });

      }).catch((error) => {
          throw new Error(error);
      });
      return `Bulk import of <%- adapterName -%> records started. You will be send an email to ${helpersAcl.getTokenFromContext(context).email} informing you about success or errors`;
  }

  static csvTableTemplate(){
    return helper.csvTableTemplate(definition);
  }

  <%- include('./includes/bulkAssociations-models', {op: "add"}); %>
  <%- include('./includes/bulkAssociations-models', {op: "remove"}); %>

  <%- include('./includes/create-models-functions', {model: adapterName}); %>
}
